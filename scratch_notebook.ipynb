{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def CopyPointCloud(input_pcd: o3d.geometry.PointCloud) -> o3d.geometry.PointCloud:\n",
    "    copy_point_cloud = o3d.geometry.PointCloud()\n",
    "\n",
    "    # copying contents\n",
    "    copy_point_cloud.points = input_pcd.points\n",
    "    copy_point_cloud.colors = input_pcd.colors\n",
    "\n",
    "    return copy_point_cloud\n",
    "\n",
    "def WritePointCloud(file_path: str, pcd: o3d.geometry.PointCloud) -> None: \n",
    "    o3d.io.write_point_cloud(file_path, pcd)\n",
    "\n",
    "def ReadCleanPointCloud(file_path: str, nb_neighbors=20, std_ratio=2.0) -> o3d.geometry.PointCloud:\n",
    "    pcd = o3d.io.read_point_cloud(file_path)\n",
    "    pcd = pcd.remove_duplicated_points()\n",
    "    pcd, _ = pcd.remove_statistical_outlier(nb_neighbors,\n",
    "                                                    std_ratio)\n",
    "    \n",
    "    return pcd\n",
    "\n",
    "def RenderPointCloud(pcd: o3d.geometry.PointCloud) -> None:\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "# def NormalizedPointCloud(pcd: o3d.geometry.PointCloud) -> o3d.geometry.PointCloud:\n",
    "#     # Load your point cloud (replace 'your_point_cloud.pcd' with the actual path)\n",
    "#     point_cloud = CopyPointCloud(pcd)\n",
    "\n",
    "#     # Get the points as a NumPy array\n",
    "#     points = np.asarray(point_cloud.points)\n",
    "\n",
    "#     # Calculate the centroid of the point cloud\n",
    "#     centroid = np.mean(points, axis=0)\n",
    "\n",
    "#     # Translate the point cloud to move the centroid to the origin (zero)\n",
    "#     normalized_points = points - centroid\n",
    "\n",
    "#     # Calculate the maximum distance from the origin to normalize the point cloud\n",
    "#     max_distance = np.max(np.linalg.norm(normalized_points, axis=1))\n",
    "\n",
    "#     # Scale the point cloud to normalize it\n",
    "#     normalized_points /= max_distance\n",
    "\n",
    "#     # Create a new point cloud with the normalized points\n",
    "#     normalized_point_cloud = o3d.geometry.PointCloud()\n",
    "#     normalized_point_cloud.points = o3d.utility.Vector3dVector(normalized_points)\n",
    "#     normalized_point_cloud.colors = point_cloud.colors\n",
    "#     normalized_point_cloud.normals = point_cloud.normals\n",
    "\n",
    "\n",
    "#     return normalized_point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = ReadCleanPointCloud('/usr/mvl2/lgsm2n/ULProj/pcd_dataset/S1/input_pcd/S1_trim.ply')\n",
    "#RenderPointCloud(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample the point cloud with a voxel of 0.005\n",
      "PointCloud with 5378 points.\n"
     ]
    }
   ],
   "source": [
    "print(\"Downsample the point cloud with a voxel of 0.005\")\n",
    "downpcd = pcd.voxel_down_sample(voxel_size=0.005)\n",
    "#o3d.visualization.draw_geometries([downpcd])\n",
    "print(downpcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing point cloud (messes with evaluation i think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "# Load your point cloud (replace 'your_point_cloud.pcd' with the actual path)\n",
    "point_cloud = CopyPointCloud(pcd)\n",
    "\n",
    "# Get the points as a NumPy array\n",
    "points = np.asarray(point_cloud.points)\n",
    "\n",
    "# Calculate the centroid of the point cloud\n",
    "centroid = np.mean(points, axis=0)\n",
    "\n",
    "# Translate the point cloud to move the centroid to the origin (zero)\n",
    "normalized_points = points - centroid\n",
    "\n",
    "# Calculate the maximum distance from the origin to normalize the point cloud\n",
    "max_distance = np.max(np.linalg.norm(normalized_points, axis=1))\n",
    "\n",
    "# Scale the point cloud to normalize it\n",
    "normalized_points /= max_distance\n",
    "\n",
    "# Create a new point cloud with the normalized points\n",
    "normalized_point_cloud = o3d.geometry.PointCloud()\n",
    "normalized_point_cloud.points = o3d.utility.Vector3dVector(normalized_points)\n",
    "normalized_point_cloud.colors = point_cloud.colors\n",
    "normalized_point_cloud.normals = point_cloud.normals\n",
    "\n",
    "# Visualize the normalized point cloud\n",
    "#o3d.visualization.draw_geometries([normalized_point_cloud])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Z value: -0.31336745619773865\n",
      "Lowest Z value: -0.6464345455169678\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "# Load your point cloud (replace 'your_point_cloud.pcd' with the actual path)\n",
    "point_cloud = CopyPointCloud(pcd) # nor normalizing now\n",
    "\n",
    "# Get the Z-coordinates of all points in the point cloud\n",
    "pts = point_cloud.points\n",
    "pts = np.asarray(pts)\n",
    "z_coordinates = pts[:, 2]\n",
    "\n",
    "# Find the highest Z value\n",
    "highest_z = z_coordinates.max()\n",
    "\n",
    "# Find the lowest Z value\n",
    "lowest_z = z_coordinates.min()\n",
    "\n",
    "print(\"Highest Z value:\", highest_z)\n",
    "print(\"Lowest Z value:\", lowest_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholding base\n",
    "\n",
    "# Load your point cloud (replace 'your_point_cloud.pcd' with the actual path)\n",
    "point_cloud = CopyPointCloud(pcd)\n",
    "\n",
    "# Define the threshold Z value below which you want to remove points\n",
    "threshold_z =lowest_z+ 0.2  # Replace with your desired threshold value\n",
    "\n",
    "# Get the Z-coordinates of all points in the point cloud\n",
    "pts = point_cloud.points\n",
    "pts = np.asarray(pts)\n",
    "z_coordinates = pts[:, 2]\n",
    "\n",
    "# Create a binary mask for points below the threshold Z value\n",
    "below_threshold_mask = z_coordinates > threshold_z\n",
    "\n",
    "# Apply the mask to filter out points below the threshold Z value\n",
    "filtered_point_cloud = point_cloud.select_by_index(np.where(below_threshold_mask)[0])\n",
    "WritePointCloud('workflow_steps/removed_base.ply', filtered_point_cloud)\n",
    "# Visualize the filtered point cloud\n",
    "#o3d.visualization.draw_geometries([filtered_point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(751, 3)\n",
      "[4 3 5 3 0 5 5 4 5 1 3 3 0 6 6 5 4 2 3 2 2 2 3 2 6 0 3 4 0 6 5 4 6 2 0 5 6\n",
      " 0 3 5 2 6 4 3 4 4 3 1 1 5 2 1 2 4 2 1 5 3 4 3 4 5 4 3 2 4 3 3 5 2 3 3 4 3\n",
      " 0 3 0 2 3 0 2 4 3 1 4 4 4 5 3 0 1 4 5 3 1 1 6 1 6 5 5 6 0 1 4 6 2 2 4 5 5\n",
      " 3 2 6 2 3 2 1 5 3 2 5 5 2 2 5 4 1 3 3 4 6 6 6 1 3 1 4 2 5 1 5 6 6 2 3 6 3\n",
      " 6 0 6 3 5 2 4 6 6 5 5 5 4 6 6 4 6 5 4 2 6 5 0 0 6 4 3 2 4 4 3 3 5 6 3 1 6\n",
      " 3 6 1 3 5 3 5 3 6 1 1 2 6 5 5 5 3 1 6 3 3 6 0 2 2 1 6 4 2 1 1 3 6 3 0 2 1\n",
      " 0 1 4 0 5 3 2 1 3 3 1 4 3 0 0 5 5 3 1 6 6 3 2 2 0 0 5 6 6 1 6 1 5 2 5 5 1\n",
      " 1 6 2 3 3 2 3 3 5 4 4 5 2 2 0 6 4 3 4 6 2 6 5 1 2 6 1 6 2 0 3 4 1 1 1 3 6\n",
      " 2 3 4 3 1 5 2 3 1 3 0 1 4 4 4 1 3 2 1 2 4 3 2 3 5 6 1 3 5 4 3 0 4 1 1 6 0\n",
      " 6 1 0 6 0 3 2 5 3 0 6 2 0 3 5 3 1 4 0 2 3 3 3 4 2 3 3 5 3 3 0 4 4 5 2 5 6\n",
      " 3 5 5 6 3 2 6 0 3 5 3 3 3 2 4 3 3 3 5 4 4 1 1 5 2 5 6 3 1 6 5 6 6 3 2 3 5\n",
      " 6 6 4 3 4 4 3 2 3 5 6 5 2 2 0 4 3 2 2 5 3 0 6 3 3 1 4 0 5 1 3 6 4 3 5 3 3\n",
      " 6 3 4 2 1 4 3 1 1 6 0 3 4 5 3 6 1 6 3 3 0 3 5 6 5 2 0 6 1 6 4 5 3 1 2 4 3\n",
      " 2 6 4 0 5 5 6 4 0 4 6 4 0 1 6 2 0 4 0 0 3 2 3 5 5 2 1 4 1 2 2 3 3 2 6 4 6\n",
      " 6 1 3 1 6 5 4 3 2 1 2 3 2 0 5 0 4 0 3 6 1 1 6 2 1 5 6 1 1 3 1 3 4 3 0 4 6\n",
      " 0 5 0 4 5 2 4 5 3 5 5 3 6 3 2 2 4 6 4 6 1 5 5 6 1 4 4 2 5 3 6 1 1 6 5 3 2\n",
      " 6 0 0 5 1 3 4 4 3 4 3 4 5 3 4 3 3 0 6 0 2 0 0 6 3 0 1 5 4 3 0 0 6 4 1 3 1\n",
      " 1 6 4 0 0 5 6 1 5 4 6 1 6 5 5 1 0 0 4 4 3 4 3 1 5 6 2 5 0 3 5 2 4 4 3 2 2\n",
      " 1 1 3 6 3 1 3 1 0 1 2 6 5 1 3 6 4 3 6 3 2 3 3 6 4 0 4 3 6 5 3 1 5 5 3 3 3\n",
      " 2 2 5 6 2 1 4 6 3 4 3 6 6 6 3 0 5 4 0 5 3 4 3 0 0 5 6 4 4 5 6 2 4 3 0 1 2\n",
      " 4 0 1 5 3 1 1 1 5 3 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gm = GaussianMixture(n_components=7, init_params='k-means++',) # could play with covariance_type='diag'\n",
    "pts = filtered_point_cloud.points\n",
    "pts = np.array(pts)\n",
    "print(pts.shape)\n",
    "colors = filtered_point_cloud.colors\n",
    "colors = np.array(colors)\n",
    "# normals = filtered_point_cloud.normals\n",
    "# normals = np.array(normals)\n",
    "# print(normals.shape)\n",
    "pts_colors = np.column_stack([pts, colors])\n",
    "labels_gm = gm.fit_predict(pts)\n",
    "print(labels_gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13597883 -0.26719002 -0.37518671]\n",
      "[[0.84693207]]\n",
      "0.22392844615221905\n"
     ]
    }
   ],
   "source": [
    "# seeing the similarity of clusters\n",
    "means = gm.means_\n",
    "print(means[6])\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial import distance\n",
    "\n",
    "vector1 = means[5]\n",
    "vector2 = means[2]\n",
    "\n",
    "similarity = cosine_similarity([vector1], [vector2])\n",
    "print(similarity)\n",
    "\n",
    "euclidean_distance = distance.euclidean(vector1, vector2)\n",
    "print(euclidean_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heirarchical clustering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1 belongs to Cluster 2\n",
      "Node 2 belongs to Cluster 1\n",
      "Node 3 belongs to Cluster 2\n",
      "Node 4 belongs to Cluster 3\n",
      "Node 5 belongs to Cluster 1\n",
      "Node 6 belongs to Cluster 1\n",
      "Node 7 belongs to Cluster 1\n",
      "[1 3 1 3 2 1 1 1 1 1 3 3 2 1 1 1 1 2 3 2 2 2 3 2 1 2 3 1 2 1 1 1 1 2 2 1 1\n",
      " 2 3 1 2 1 1 3 1 1 3 1 1 1 2 1 2 1 2 1 1 3 1 3 1 1 1 3 2 1 3 3 1 2 3 3 1 3\n",
      " 2 3 2 2 3 2 2 1 3 1 1 1 1 1 3 2 1 1 1 3 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1\n",
      " 3 2 1 2 3 2 1 1 3 2 1 1 2 2 1 1 1 3 3 1 1 1 1 1 3 1 1 2 1 1 1 1 1 2 3 1 3\n",
      " 1 2 1 3 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 2 1 1 3 2 1 1 3 3 1 1 3 1 1\n",
      " 3 1 1 3 1 3 1 3 1 1 1 2 1 1 1 1 3 1 1 3 3 1 2 2 2 1 1 1 2 1 1 3 1 3 2 2 1\n",
      " 2 1 1 2 1 3 2 1 3 3 1 1 3 2 2 1 1 3 1 1 1 3 2 2 2 2 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 2 3 3 2 3 3 1 1 1 1 2 2 2 1 1 3 1 1 2 1 1 1 2 1 1 1 2 2 3 1 1 1 1 3 1\n",
      " 2 3 1 3 1 1 2 3 1 3 2 1 1 1 1 1 3 2 1 2 1 3 2 3 1 1 1 3 1 1 3 2 1 1 1 1 2\n",
      " 1 1 2 1 2 3 2 1 3 2 1 2 2 3 1 3 1 1 2 2 3 3 3 1 2 3 3 1 3 3 2 1 1 1 2 1 1\n",
      " 3 1 1 1 3 2 1 2 3 1 3 3 3 2 1 3 3 3 1 1 1 1 1 1 2 1 1 3 1 1 1 1 1 3 2 3 1\n",
      " 1 1 1 3 1 1 3 2 3 1 1 1 2 2 2 1 3 2 2 1 3 2 1 3 3 1 1 2 1 1 3 1 1 3 1 3 3\n",
      " 1 3 1 2 1 1 3 1 1 1 2 3 1 1 3 1 1 1 3 3 2 3 1 1 1 2 2 1 1 1 1 1 3 1 2 1 3\n",
      " 2 1 1 2 1 1 1 1 2 1 1 1 2 1 1 2 2 1 2 2 3 2 3 1 1 2 1 1 1 2 2 3 3 2 1 1 1\n",
      " 1 1 3 1 1 1 1 3 2 1 2 3 2 2 1 2 1 2 3 1 1 1 1 2 1 1 1 1 1 3 1 3 1 3 2 1 1\n",
      " 2 1 2 1 1 2 1 1 3 1 1 3 1 3 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 3 1 1 1 1 1 3 2\n",
      " 1 2 2 1 1 3 1 1 3 1 3 1 1 3 1 3 3 2 1 2 2 2 2 1 3 2 1 1 1 3 2 2 1 1 1 3 1\n",
      " 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 3 1 3 1 1 1 2 1 2 3 1 2 1 1 3 2 2\n",
      " 1 1 3 1 3 1 3 1 2 1 2 1 1 1 3 1 1 3 1 3 2 3 3 1 1 2 1 3 1 1 3 1 1 1 3 3 3\n",
      " 2 2 1 1 2 1 1 1 3 1 3 1 1 1 3 2 1 1 2 1 3 1 3 2 2 1 1 1 1 1 1 2 1 3 2 1 2\n",
      " 1 2 1 1 3 1 1 1 1 3 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4107250/1883245739.py:15: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  linkage_matrix = linkage(distance_matrix, method='ward')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Calculate pairwise distances using pdist\n",
    "distances = pdist(means, metric='euclidean')\n",
    "\n",
    "# Convert the pairwise distances to a square distance matrix using squareform\n",
    "distance_matrix = squareform(distances)\n",
    "\n",
    "# Specify the number of clusters (in this case, 3)\n",
    "num_clusters = 3\n",
    "\n",
    "# Compute the linkage matrix\n",
    "linkage_matrix = linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Perform hierarchical clustering and assign nodes to clusters\n",
    "cluster_labels = fcluster(linkage_matrix, t=num_clusters, criterion='maxclust')\n",
    "\n",
    "# Print cluster assignments\n",
    "for node, cluster in enumerate(cluster_labels):\n",
    "    print(f\"Node {node + 1} belongs to Cluster {cluster}\")\n",
    "\n",
    "heirarchical_labels = cluster_labels[labels_gm]\n",
    "print(heirarchical_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normals Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PointCloud with 74 points., PointCloud with 98 points., PointCloud with 93 points., PointCloud with 160 points., PointCloud with 106 points., PointCloud with 108 points., PointCloud with 112 points.]\n",
      "[-0.77499007  0.21066302  0.48204593]\n",
      "[ 0.31062284 -0.53162633  0.77476794]\n",
      "[-0.79121165  0.26892034  0.35221714]\n",
      "[0.70130099 0.54785478 0.07509219]\n",
      "[ 0.12977645 -0.97038545  0.17969814]\n",
      "[0.42850571 0.14257463 0.85871096]\n",
      "[ 0.24503982 -0.84711538  0.44767508]\n",
      "Node 1 belongs to Cluster 1\n",
      "Node 2 belongs to Cluster 2\n",
      "Node 3 belongs to Cluster 1\n",
      "Node 4 belongs to Cluster 2\n",
      "Node 5 belongs to Cluster 2\n",
      "Node 6 belongs to Cluster 2\n",
      "Node 7 belongs to Cluster 2\n",
      "[2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 1 2 1 1 1 2 1 2 1 2 2 1 2 2 2 2 1 1 2 2\n",
      " 1 2 2 1 2 2 2 2 2 2 2 2 2 1 2 1 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2 2 2\n",
      " 1 2 1 1 2 1 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 1 2 2 2\n",
      " 2 1 2 1 2 1 2 2 2 1 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 1 2 2 2\n",
      " 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 1 2 2 2 1 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 1 1 2 2 2 1 2 2 2 2 2 1 1 2\n",
      " 1 2 2 1 2 2 1 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2 2 1 2 2 2\n",
      " 2 2 1 2 2 1 2 2 2 2 2 2 1 1 1 2 2 2 2 2 1 2 2 2 1 2 2 2 1 1 2 2 2 2 2 2 2\n",
      " 1 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 1 2 1 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2 1\n",
      " 2 2 1 2 1 2 1 2 2 1 2 1 1 2 2 2 2 2 1 1 2 2 2 2 1 2 2 2 2 2 1 2 2 2 1 2 2\n",
      " 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2\n",
      " 2 2 2 2 2 2 2 1 2 2 2 2 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 1 2 2 2 2 2 2 2 1 2 2\n",
      " 1 2 2 1 2 2 2 2 1 2 2 2 1 2 2 1 1 2 1 1 2 1 2 2 2 1 2 2 2 1 1 2 2 1 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 1 2 1 1 2 1 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 2\n",
      " 1 2 1 2 2 1 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1\n",
      " 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 1 1 1 2 2 1 2 2 2 2 1 1 2 2 2 2 2\n",
      " 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 1 2 1 2 2 1 2 2 2 1 1\n",
      " 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 1 1 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 1 1 2 2 2 2 2 2 1 2 2 1 2 1\n",
      " 2 1 2 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4107250/3136372841.py:46: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  linkage_matrix = linkage(distance_matrix, method='ward')\n"
     ]
    }
   ],
   "source": [
    "# Goal: find average normal of each cluster and cluster together to separate leaves\n",
    "segments = segment_point_cloud(filtered_point_cloud, labels_gm)\n",
    "print(segments)\n",
    "\n",
    "def estimate_normals(point_cloud, search_param = o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30)):\n",
    "    \"\"\"\n",
    "    Estimate normals for the point cloud.\n",
    "\n",
    "    :param point_cloud: Open3D point cloud object.\n",
    "    :param search_param: Parameters for KDTree search in normal estimation.\n",
    "    :return: Point cloud with estimated normals.\n",
    "    \"\"\"\n",
    "    point_cloud.estimate_normals(search_param=search_param)\n",
    "    point_cloud.orient_normals_consistent_tangent_plane(k=30)\n",
    "    return point_cloud\n",
    "\n",
    "def calculate_average_normal(point_cloud):\n",
    "    \"\"\"\n",
    "    Calculate the average normal vector of the point cloud.\n",
    "\n",
    "    :param point_cloud: Point cloud with normals.\n",
    "    :return: Average normal vector.\n",
    "    \"\"\"\n",
    "    normals = np.asarray(point_cloud.normals)\n",
    "    average_normal = np.mean(normals, axis=0)\n",
    "    return average_normal\n",
    "\n",
    "# finding normals\n",
    "normals = []\n",
    "for segment in segments:\n",
    "    segment = estimate_normals(segment)\n",
    "    avg_normal = calculate_average_normal(segment)\n",
    "    print(avg_normal)\n",
    "    normals.append(avg_normal)\n",
    "\n",
    "# Calculate pairwise distances using pdist\n",
    "distances = pdist(normals, metric='cosine')\n",
    "\n",
    "# Convert the pairwise distances to a square distance matrix using squareform\n",
    "distance_matrix = squareform(distances)\n",
    "\n",
    "# Specify the number of clusters (in this case, 3)\n",
    "num_clusters = 2\n",
    "\n",
    "# Compute the linkage matrix\n",
    "linkage_matrix = linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Perform hierarchical clustering and assign nodes to clusters\n",
    "cluster_labels = fcluster(linkage_matrix, t=num_clusters, criterion='maxclust')\n",
    "\n",
    "# Print cluster assignments\n",
    "for node, cluster in enumerate(cluster_labels):\n",
    "    print(f\"Node {node + 1} belongs to Cluster {cluster}\")\n",
    "\n",
    "heirarchical_labels = cluster_labels[labels_gm]\n",
    "print(heirarchical_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_point_cloud(point_cloud, labels):\n",
    "    rgb_values = [\n",
    "        [0.89411765, 0.10196078, 0.10980392],\n",
    "        [0.21568627, 0.49411765, 0.72156863],\n",
    "        [0.30196078, 0.68627451, 0.29019608],\n",
    "        [0.59607843, 0.30588235, 0.63921569],\n",
    "        [1.0, 0.49803922, 0.0],\n",
    "        [1.0, 1.0, 0.2],\n",
    "        [0.65098039, 0.3372549, 0.15686275],\n",
    "        [0.96862745, 0.50588235, 0.74901961],\n",
    "        [0.6, 0.6, 0.6],\n",
    "        [0.89411765, 0.10196078, 0.10980392],\n",
    "        [0.89411765, 0.10196078, 0.10980392],\n",
    "        [0.21568627, 0.49411765, 0.72156863],\n",
    "        [0.30196078, 0.68627451, 0.29019608],\n",
    "        [0.59607843, 0.30588235, 0.63921569],\n",
    "        [1.0, 0.49803922, 0.0],\n",
    "        [1.0, 1.0, 0.2],\n",
    "        [0.65098039, 0.3372549, 0.15686275],\n",
    "        [0.96862745, 0.50588235, 0.74901961],\n",
    "        [0.6, 0.6, 0.6],\n",
    "        [0.89411765, 0.10196078, 0.10980392]\n",
    "    ]\n",
    "\n",
    "    # Create an empty segmented point cloud\n",
    "    segmented_pc = o3d.geometry.PointCloud()\n",
    "    \n",
    "    # Assign cluster labels to each point\n",
    "    segmented_pc.points = o3d.utility.Vector3dVector(point_cloud.points)\n",
    "    segmented_pc.colors = o3d.utility.Vector3dVector(np.zeros_like(point_cloud.colors))\n",
    "    for i, label in enumerate(labels):\n",
    "        value = rgb_values[label]\n",
    "        segmented_pc.colors[i] = value\n",
    "        #segmented_pc.colors[i] = point_cloud.colors[i] if label != -1 else [0, 0, 0]  # Set unclustered points to black\n",
    "    \n",
    "    return segmented_pc\n",
    "\n",
    "# Segment the point cloud based on the labels and centroids\n",
    "segmented_pc_gm = segment_point_cloud(filtered_point_cloud, heirarchical_labels) # usually labe\n",
    "WritePointCloud('workflow_steps/heir_step.ply', segmented_pc_gm)\n",
    "# Visualize the segmented point cloud\n",
    "o3d.visualization.draw_geometries([segmented_pc_gm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### seeing if similar normals allow for combining clusters\n",
    "def segment_point_cloud(point_cloud, labels):\n",
    "    clouds = []\n",
    "    #segmented_cloud = o3d.geometry.PointCloud()\n",
    "\n",
    "    # Convert the labels list to a NumPy array\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    # Get unique labels\n",
    "    unique_labels = np.unique(labels)\n",
    "\n",
    "    # Iterate over unique labels and extract points belonging to each segment\n",
    "    for label in unique_labels:\n",
    "        mask = labels == label\n",
    "        segment_points = np.asarray(point_cloud.points)[mask]\n",
    "        segment_colors = np.asarray(point_cloud.colors)[mask]\n",
    "        segment_cloud = o3d.geometry.PointCloud()\n",
    "        segment_cloud.points = o3d.utility.Vector3dVector(segment_points)\n",
    "        segment_cloud.colors = o3d.utility.Vector3dVector(segment_colors)\n",
    "        clouds.append(segment_cloud)\n",
    "\n",
    "    return clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PointCloud with 124 points., PointCloud with 149 points., PointCloud with 234 points.]\n"
     ]
    }
   ],
   "source": [
    "segmented_pcd = segment_point_cloud(filtered_point_cloud, heirarchical_labels)\n",
    "print(segmented_pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NormalizedPointCloud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb Cell 19\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m ground_truth_pc \u001b[39m=\u001b[39m o3d\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mread_point_cloud(\u001b[39m\"\u001b[39m\u001b[39m/usr/mvl2/lgsm2n/ULProj/pcd_dataset/S4/S4_trimmed_leaf1.ply\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# RenderPointCloud(ground_truth_pc)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m ground_truth_pc_normalized \u001b[39m=\u001b[39m NormalizedPointCloud(ground_truth_pc)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# RenderPointCloud(ground_truth_pc_normalized)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# Find matching and non-matching points\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m matching, non_matching_pred, non_matching_gt \u001b[39m=\u001b[39m find_matching_and_non_matching_points(predicted_pc, ground_truth_pc)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NormalizedPointCloud' is not defined"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "def find_matching_and_non_matching_points(predicted_pc, ground_truth_pc, tolerance=0.001):\n",
    "    \"\"\"\n",
    "    Find matching and non-matching points between a predicted point cloud and a ground truth point cloud.\n",
    "\n",
    "    Args:\n",
    "    - predicted_pc: Open3D PointCloud object representing the predicted point cloud.\n",
    "    - ground_truth_pc: Open3D PointCloud object representing the ground truth point cloud.\n",
    "    - tolerance: A distance tolerance threshold for considering points as matching (default is 0.001).\n",
    "\n",
    "    Returns:\n",
    "    - matching_points: Indices of matching points in the predicted point cloud.\n",
    "    - non_matching_predicted_points: Indices of non-matching points in the predicted point cloud.\n",
    "    - non_matching_ground_truth_points: Indices of non-matching points in the ground truth point cloud.\n",
    "    \"\"\"\n",
    "    # Convert point clouds to NumPy arrays for efficient processing\n",
    "    predicted_points = np.asarray(predicted_pc.points)\n",
    "    ground_truth_points = np.asarray(ground_truth_pc.points)\n",
    "\n",
    "    # Find matching points within the specified tolerance\n",
    "    matching_points = []\n",
    "    non_matching_predicted_points = []\n",
    "    non_matching_ground_truth_points = []\n",
    "\n",
    "    for i, pred_point in enumerate(predicted_points):\n",
    "        closest_distance = np.min(np.linalg.norm(ground_truth_points - pred_point, axis=1))\n",
    "        if closest_distance <= tolerance:\n",
    "            matching_points.append(i)\n",
    "        else:\n",
    "            non_matching_predicted_points.append(i)\n",
    "\n",
    "    # Find non-matching points in the ground truth point cloud\n",
    "    for j, gt_point in enumerate(ground_truth_points):\n",
    "        closest_distance = np.min(np.linalg.norm(predicted_points - gt_point, axis=1))\n",
    "        if closest_distance > tolerance:\n",
    "            non_matching_ground_truth_points.append(j)\n",
    "\n",
    "    return matching_points, non_matching_predicted_points, non_matching_ground_truth_points\n",
    "\n",
    "# Example usage:\n",
    "# Load the predicted and ground truth point clouds\n",
    "predicted_pc = CopyPointCloud(segmented_pcd[0])  #o3d.io.read_point_cloud(\"predicted_point_cloud.pcd\")\n",
    "#predicted_pc = o3d.io.read_point_cloud('/usr/mvl2/lgsm2n/ULProj/pcd_dataset/S1/S1_trim.ply')  #o3d.io.read_point_cloud(\"predicted_point_cloud.pcd\")\n",
    "# RenderPointCloud(predicted_pc)\n",
    "ground_truth_pc = o3d.io.read_point_cloud(\"/usr/mvl2/lgsm2n/ULProj/pcd_dataset/S4/S4_trimmed_leaf1.ply\")\n",
    "# RenderPointCloud(ground_truth_pc)\n",
    "ground_truth_pc_normalized = NormalizedPointCloud(ground_truth_pc)\n",
    "# RenderPointCloud(ground_truth_pc_normalized)\n",
    "\n",
    "# Find matching and non-matching points\n",
    "matching, non_matching_pred, non_matching_gt = find_matching_and_non_matching_points(predicted_pc, ground_truth_pc)\n",
    "print(len(matching))\n",
    "# Visualize the results or perform further analysis as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb Cell 20\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m precision \u001b[39m=\u001b[39m calculate_precision(matching, non_matching_pred)  \u001b[39m# Pass matching and non_matching_pred here\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m recall \u001b[39m=\u001b[39m calculate_recall(matching, non_matching_gt)  \u001b[39m# Pass matching and non_matching_gt here\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m f1 \u001b[39m=\u001b[39m calculate_f1_score(matching, non_matching_pred, non_matching_gt)  \u001b[39m# Pass all three arguments here\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe IOU score is \u001b[39m\u001b[39m{\u001b[39;00miou\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe precision is \u001b[39m\u001b[39m{\u001b[39;00mprecision\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m precision \u001b[39m=\u001b[39m calculate_precision(matching, non_matching_pred)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m recall \u001b[39m=\u001b[39m calculate_recall(matching, non_matching_gt)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m f1_score \u001b[39m=\u001b[39m \u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m (precision \u001b[39m*\u001b[39;49m recall) \u001b[39m/\u001b[39;49m (precision \u001b[39m+\u001b[39;49m recall)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mreturn\u001b[39;00m f1_score\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "def calculate_iou(matching, non_matching_pred, non_matching_gt):\n",
    "    intersection = len(matching)\n",
    "    union = len(non_matching_pred) + len(non_matching_gt) + intersection\n",
    "    iou = intersection / union\n",
    "    return iou\n",
    "\n",
    "def calculate_precision(matching, non_matching_pred):\n",
    "    true_positives = len(matching)\n",
    "    false_positives = len(non_matching_pred)\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    return precision\n",
    "\n",
    "def calculate_recall(matching, non_matching_gt):\n",
    "    true_positives = len(matching)\n",
    "    false_negatives = len(non_matching_gt)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def calculate_f1_score(matching, non_matching_pred, non_matching_gt):\n",
    "    precision = calculate_precision(matching, non_matching_pred)\n",
    "    recall = calculate_recall(matching, non_matching_gt)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score\n",
    "\n",
    "# iou = calculate_iou(matching=matching, non_matching_pred=non_matching_pred, non_matching_gt=non_matching_gt)\n",
    "# precision = calculate_iou(matching=matching, non_matching_pred=non_matching_pred)\n",
    "# recall = calculate_iou(matching=matching, non_matching_gt=non_matching_gt)\n",
    "# f1 = calculate_iou(matching=matching, non_matching_pred=non_matching_pred, non_matching_gt=non_matching_gt)\n",
    "\n",
    "# print(f'The IOU score is {iou}')\n",
    "# print(f'The precision is {precision}')\n",
    "# print(f'The recall is {recall}')\n",
    "# print(f'The F1 score is {f1}')\n",
    "iou = calculate_iou(matching=matching, non_matching_pred=non_matching_pred, non_matching_gt=non_matching_gt)\n",
    "precision = calculate_precision(matching, non_matching_pred)  # Pass matching and non_matching_pred here\n",
    "recall = calculate_recall(matching, non_matching_gt)  # Pass matching and non_matching_gt here\n",
    "f1 = calculate_f1_score(matching, non_matching_pred, non_matching_gt)  # Pass all three arguments here\n",
    "\n",
    "print(f'The IOU score is {iou}')\n",
    "print(f'The precision is {precision}')\n",
    "print(f'The recall is {recall}')\n",
    "print(f'The F1 score is {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.8070953436807096\n",
      "Precision: 0.9479166666666666\n",
      "Recall: 0.8445475638051044\n",
      "F1 Score: 0.8932515337423312\n"
     ]
    }
   ],
   "source": [
    "from evaluation import PointCloudMetricsCalculator\n",
    "\n",
    "predicted_pc = CopyPointCloud(segmented_pcd[0])  #o3d.io.read_point_cloud(\"predicted_point_cloud.pcd\")\n",
    "ground_truth_pc = o3d.io.read_point_cloud(\"/usr/mvl2/lgsm2n/ULProj/pcd_dataset/S4/S4_trimmed_leaf1.ply\")\n",
    "\n",
    "# Create an instance of the PointCloudMetricsCalculator\n",
    "calculator = PointCloudMetricsCalculator(predicted_pc, ground_truth_pc)\n",
    "\n",
    "# Calculate all metrics\n",
    "metrics = calculator.CalculateMetrics()\n",
    "\n",
    "# Print the metrics\n",
    "for metric_name, metric_value in metrics.items():\n",
    "    print(f'{metric_name}: {metric_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Class\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'points'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb Cell 23\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m seg_class \u001b[39m=\u001b[39m SegmentLeavesPCD()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m ground_truth_pc \u001b[39m=\u001b[39m o3d\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mread_point_cloud(\u001b[39m\"\u001b[39m\u001b[39m/usr/mvl2/lgsm2n/ULProj/pcd_dataset/S5/S5_trimmed_leaf1.ply\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m segments \u001b[39m=\u001b[39m seg_class\u001b[39m.\u001b[39;49mSegmentLeaves(\u001b[39m'\u001b[39;49m\u001b[39m/usr/mvl2/lgsm2n/ULProj/pcd_dataset/S5/S5_trimmed.ply\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m segment \u001b[39min\u001b[39;00m segments:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Create an instance of the PointCloudMetricsCalculator\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmeru2/usr/mvl2/lgsm2n/ULProj/clean_pcd.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39meval\u001b[39m \u001b[39m=\u001b[39m  PointCloudMetricsCalculator(segment, ground_truth_pc)\n",
      "File \u001b[0;32m~/ULProj/segment_pcd.py:163\u001b[0m, in \u001b[0;36mSegmentLeavesPCD.SegmentLeaves\u001b[0;34m(self, input_pcd)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mSegmentLeaves\u001b[39m(\u001b[39mself\u001b[39m, pcd_path: \u001b[39mstr\u001b[39m):\n\u001b[1;32m    162\u001b[0m     \u001b[39m# read pcd \u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m     input_pcd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mReadCleanPointCloud(pcd_path)\n\u001b[1;32m    165\u001b[0m     \u001b[39m# step 1 remove the base of the pcd\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     removed_base_pcd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mRemoveBase(input_pcd)\n",
      "File \u001b[0;32m~/ULProj/segment_pcd.py:38\u001b[0m, in \u001b[0;36mSegmentLeavesPCD.RemoveBase\u001b[0;34m(self, pcd, z_level)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mRemoveBase\u001b[39m(\u001b[39mself\u001b[39m, pcd: o3d\u001b[39m.\u001b[39mgeometry\u001b[39m.\u001b[39mPointCloud, z_level: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m):\n\u001b[1;32m     37\u001b[0m     \u001b[39m# Load your point cloud (replace 'your_point_cloud.pcd' with the actual path)\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     point_cloud \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mCopyPointCloud(pcd) \u001b[39m# nor normalizing now\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[39m# Get the Z-coordinates of all points in the point cloud\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     pts \u001b[39m=\u001b[39m point_cloud\u001b[39m.\u001b[39mpoints\n",
      "File \u001b[0;32m~/ULProj/segment_pcd.py:20\u001b[0m, in \u001b[0;36mSegmentLeavesPCD.CopyPointCloud\u001b[0;34m(self, input_pcd)\u001b[0m\n\u001b[1;32m     17\u001b[0m copy_point_cloud \u001b[39m=\u001b[39m o3d\u001b[39m.\u001b[39mgeometry\u001b[39m.\u001b[39mPointCloud()\n\u001b[1;32m     19\u001b[0m \u001b[39m# copying contents\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m copy_point_cloud\u001b[39m.\u001b[39mpoints \u001b[39m=\u001b[39m input_pcd\u001b[39m.\u001b[39;49mpoints\n\u001b[1;32m     21\u001b[0m copy_point_cloud\u001b[39m.\u001b[39mcolors \u001b[39m=\u001b[39m input_pcd\u001b[39m.\u001b[39mcolors\n\u001b[1;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m copy_point_cloud\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'points'"
     ]
    }
   ],
   "source": [
    "from segment_pcd import SegmentLeavesPCD\n",
    "from evaluation import PointCloudMetricsCalculator\n",
    "\n",
    "seg_class = SegmentLeavesPCD()\n",
    "ground_truth_pc = o3d.io.read_point_cloud(\"/usr/mvl2/lgsm2n/ULProj/pcd_dataset/S5/S5_trimmed_leaf1.ply\")\n",
    "\n",
    "segments = seg_class.SegmentLeaves('/usr/mvl2/lgsm2n/ULProj/pcd_dataset/S5/S5_trimmed.ply')\n",
    "\n",
    "for segment in segments:\n",
    "    # Create an instance of the PointCloudMetricsCalculator\n",
    "    eval =  PointCloudMetricsCalculator(segment, ground_truth_pc)\n",
    "\n",
    "    # Calculate all metrics\n",
    "    metrics = eval.CalculateMetrics()\n",
    "\n",
    "    # Print the metrics\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        print(f'{metric_name}: {metric_value}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
